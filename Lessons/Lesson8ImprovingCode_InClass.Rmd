---
title: "Lesson 8 Improving Code"
author: "Karsten Maurer"
date: "9/27/2019"
output: 
  html_document:
    number_sections: true
    pandoc_args: [
      "--number-sections",
      "--number-offset=7"
      ]
editor_options: 
  chunk_output_type: console
---

# Simulation Study Efficiency

In our example code from Monday we implemented a number of functions to run a sumulation study on the comparison of stepwise and lasso variable selection methods. It all ran, but was a bit slow... and was a bit of a mess. Today we will talk about speeding it up and cleaning it up. 

```{r example_var_select, warning=FALSE, message=FALSE}
### Libraries we will need containing the functions required
library(tidyverse)
library(glmnet)
library(caret)
library(tictoc)
library(parallel)
library(devtools)
# devtools::install_github('nathanvan/parallelsugar')
library(parallelsugar)

source("SimStudyHelperFunctions_InClass.R")

sim_var_select(10, 500, 10, 5, var_select_ftn=step_var_mod)
```

## Running Code in Parallel

```{r after_profiled, cache=T}
## Possible parameter combinations
params <- expand.grid(n=c(50,100,200), p=c(20,25,30), q=c(5,10))

tic()
sim_results <- lapply(1:nrow(params), function(i){
        sim_var_select(n=params$n[i], p=params$p[i], q=params$q[i],
                       n_sim=3,var_select_ftn=step_var_mod )
       })
toc()

### Parallel Processing: 
## parallel package by Luke Tierney
# easy with lapply and mapply --> mclapply and mcmapply on Mac and Linux
# Hard on Windows which want to use seriel processing 
## parallelsugar package by Nathan VanHoudnos gives windows hacked version
tic()
sim_results2 <- mclapply(1:nrow(params), function(i){
        sim_var_select(n=params$n[i], p=params$p[i], q=params$q[i],
                       n_sim=3,var_select_ftn=step_var_mod )
       })
toc()

# Note that after changing from CV RMSE values to bootstrap RMSE values,
# the parallel processing is actually slower. 
```

## Code Profiling

How do we identify which stages in our code are slow? Profiling code is the process of investigating and timing the stages sequentially to identify the slow components, also known as *bottlenecks*. 

```{r profiling_code, error=FALSE, eval=FALSE}
### Profiling code with Rprof utility function
utils::Rprof(tmp <- tempfile())
sim_var_select(n_sim=10, n=100, p=10, q=5, var_select_ftn=step_var_mod)
Rprof()
summaryRprof(tmp)
unlink(tmp)

#----------------------
# In the profiling steps below we can uncomment the computational stages
# one at a time to see which part of the process is the "bottleneck"
utils::Rprof(tmp <- tempfile())
sim_data_example <- make_sim_data(n=100, p=20, q=10, b=0.1, sd_y=1, sd_x=1)
# step_example <- step_var_mod(sim_data_example)
# rmse_example <- select_cv_rmse(step_example)
Rprof()
summaryRprof(tmp)
unlink(tmp)
```

## After Profiling

```{r parallelization, cache=T}
## Possible parameter combinations
params <- expand.grid(n=c(50,100,200), p=c(20,25,30), q=c(5,10))

tic()
sim_results <- lapply(1:nrow(params), function(i){
        sim_var_select(n=params$n[i], p=params$p[i], q=params$q[i],
                       n_sim=3,var_select_ftn=step_var_mod, boot=TRUE)
       })
toc()

### Parallel Processing: 
## parallel package by Luke Tierney
# easy with lapply and mapply --> mclapply and mcmapply on Mac and Linux
# Hard on Windows which want to use seriel processing 
## parallelsugar package by Nathan VanHoudnos gives windows hacked version
tic()
sim_results2 <- mclapply(1:nrow(params), function(i){
        sim_var_select(n=params$n[i], p=params$p[i], q=params$q[i],
                       n_sim=3,var_select_ftn=step_var_mod, boot=TRUE)
       })
toc()

# Note that after changing from CV RMSE values to bootstrap RMSE values,
# the parallel processing is actually slower. 
```
